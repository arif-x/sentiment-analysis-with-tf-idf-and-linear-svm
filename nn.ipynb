{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(100)\n",
        "\n",
        "class Layer:\n",
        "    \"\"\"\n",
        "    Represents a layer (hidden or output) in our neural network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_input, n_neurons, activation=None, weights=None, bias=None):\n",
        "        \"\"\"\n",
        "        :param int n_input: The input size (coming from the input layer or a previous hidden layer)\n",
        "        :param int n_neurons: The number of neurons in this layer.\n",
        "        :param str activation: The activation function to use (if any).\n",
        "        :param weights: The layer's weights.\n",
        "        :param bias: The layer's bias.\n",
        "        \"\"\"\n",
        "\n",
        "        self.weights = weights if weights is not None else np.random.randn(n_input, n_neurons)\n",
        "        self.activation = activation\n",
        "        self.bias = bias if bias is not None else np.random.randn(n_neurons)\n",
        "        self.last_activation = None\n",
        "        self.error = None\n",
        "        self.delta = None\n",
        "\n",
        "    def activate(self, x):\n",
        "        \"\"\"\n",
        "        Calculates the dot product of this layer.\n",
        "        :param x: The input.\n",
        "        :return: The result.\n",
        "        \"\"\"\n",
        "\n",
        "        r = np.dot(x, self.weights) + self.bias\n",
        "        self.last_activation = self._apply_activation(r)\n",
        "        return self.last_activation\n",
        "\n",
        "    def _apply_activation(self, r):\n",
        "        \"\"\"\n",
        "        Applies the chosen activation function (if any).\n",
        "        :param r: The normal value.\n",
        "        :return: The \"activated\" value.\n",
        "        \"\"\"\n",
        "\n",
        "        # In case no activation function was chosen\n",
        "        if self.activation is None:\n",
        "            return r\n",
        "\n",
        "        # tanh\n",
        "        if self.activation == 'tanh':\n",
        "            return np.tanh(r)\n",
        "\n",
        "        # sigmoid\n",
        "        if self.activation == 'sigmoid':\n",
        "            return 1 / (1 + np.exp(-r))\n",
        "\n",
        "        return r\n",
        "\n",
        "    def apply_activation_derivative(self, r):\n",
        "        \"\"\"\n",
        "        Applies the derivative of the activation function (if any).\n",
        "        :param r: The normal value.\n",
        "        :return: The \"derived\" value.\n",
        "        \"\"\"\n",
        "\n",
        "        # We use 'r' directly here because its already activated, the only values that\n",
        "        # are used in this function are the last activations that were saved.\n",
        "\n",
        "        if self.activation is None:\n",
        "            return r\n",
        "\n",
        "        if self.activation == 'tanh':\n",
        "            return 1 - r ** 2\n",
        "\n",
        "        if self.activation == 'sigmoid':\n",
        "            return r * (1 - r)\n",
        "\n",
        "        return r\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    \"\"\"\n",
        "    Represents a neural network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._layers = []\n",
        "\n",
        "    def add_layer(self, layer):\n",
        "        \"\"\"\n",
        "        Adds a layer to the neural network.\n",
        "        :param Layer layer: The layer to add.\n",
        "        \"\"\"\n",
        "\n",
        "        self._layers.append(layer)\n",
        "\n",
        "    def feed_forward(self, X):\n",
        "        \"\"\"\n",
        "        Feed forward the input through the layers.\n",
        "        :param X: The input values.\n",
        "        :return: The result.\n",
        "        \"\"\"\n",
        "\n",
        "        for layer in self._layers:\n",
        "            X = layer.activate(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts a class (or classes).\n",
        "        :param X: The input values.\n",
        "        :return: The predictions.\n",
        "        \"\"\"\n",
        "\n",
        "        ff = self.feed_forward(X)\n",
        "        return ff\n",
        "        \"\"\"\n",
        "        # One row\n",
        "        if ff.ndim == 1:\n",
        "            return np.argmax(ff)\n",
        "        # Multiple rows\n",
        "        return np.argmax(ff, axis=1)\n",
        "        \"\"\"\n",
        "    def backpropagation(self, X, y, learning_rate):\n",
        "        \"\"\"\n",
        "        Performs the backward propagation algorithm and updates the layers weights.\n",
        "        :param X: The input values.\n",
        "        :param y: The target values.\n",
        "        :param float learning_rate: The learning rate (between 0 and 1).\n",
        "        \"\"\"\n",
        "\n",
        "        # Feed forward for the output\n",
        "        output = self.feed_forward(X)\n",
        "\n",
        "        # Loop over the layers backward\n",
        "        for i in reversed(range(len(self._layers))):\n",
        "            layer = self._layers[i]\n",
        "\n",
        "            # If this is the output layer\n",
        "            if layer == self._layers[-1]:\n",
        "                layer.error = y - output\n",
        "                # The output = layer.last_activation in this case\n",
        "                layer.delta = layer.error * layer.apply_activation_derivative(output)\n",
        "            else:\n",
        "                next_layer = self._layers[i + 1]\n",
        "                layer.error = np.dot(next_layer.weights, next_layer.delta)\n",
        "                layer.delta = layer.error * layer.apply_activation_derivative(layer.last_activation)\n",
        "\n",
        "        # Update the weights\n",
        "        for i in range(len(self._layers)):\n",
        "            layer = self._layers[i]\n",
        "            # The input is either the previous layers output or X itself (for the first hidden layer)\n",
        "            input_to_use = np.atleast_2d(X if i == 0 else self._layers[i - 1].last_activation)\n",
        "            layer.weights += layer.delta * input_to_use.T * learning_rate\n",
        "\n",
        "    def train(self, X, y, learning_rate, max_epochs):\n",
        "        \"\"\"\n",
        "        Trains the neural network using backpropagation.\n",
        "        :param X: The input values.\n",
        "        :param y: The target values.\n",
        "        :param float learning_rate: The learning rate (between 0 and 1).\n",
        "        :param int max_epochs: The maximum number of epochs (cycles).\n",
        "        :return: The list of calculated MSE errors.\n",
        "        \"\"\"\n",
        "\n",
        "        mses = []\n",
        "        for i in range(max_epochs):\n",
        "            temp_mses = []\n",
        "            for j in range(len(X)):\n",
        "                self.backpropagation(X[j], y[j], learning_rate)\n",
        "                mse = np.mean(np.square(y - nn.feed_forward(X)))\n",
        "                temp_mses.append(mse)\n",
        "            mses.append(sum(temp_mses) / len(temp_mses))\n",
        "            print('Epoch: #%s, MSE: %f' % (i+1, float(mse)))\n",
        "        return mses\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Calculates the accuracy between the predicted labels and true labels.\n",
        "        :param y_pred: The predicted labels.\n",
        "        :param y_true: The true labels.\n",
        "        :return: The calculated accuracy.\n",
        "        \"\"\"\n",
        "\n",
        "        return ((np.round(y_pred,1)== y_true)).mean()"
      ],
      "metadata": {
        "id": "7nqtrrJQ6VXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])"
      ],
      "metadata": {
        "id": "zAuKcZqjOLVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NeuralNetwork()\n",
        "nn.add_layer(Layer(2, 10, 'tanh'))\n",
        "nn.add_layer(Layer(10, 1, 'sigmoid'))\n",
        "\n",
        "# Define dataset XOR\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Train the neural network\n",
        "errors = nn.train(X, y, 0.75, 300)\n",
        "print(\"Accuracy: %.2f%%\" % (nn.accuracy(nn.predict(X)[:,0].T, y.flatten()) * 100))\n",
        "print(\"Data ouput: \\n\" + str(y))\n",
        "print(\"Predicted output: \\n\" + str(nn.predict(X)))\n",
        "print(\"Predicted output round: \\n\" + str(np.round(nn.predict(X),1)))\n",
        "\n",
        "# Plot changes in mse\n",
        "plt.plot(errors, c = 'b', label = 'MSE')\n",
        "plt.title('Changes in MSE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.grid(linestyle='-.', linewidth=0.5)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rT3rMRuM66Kq",
        "outputId": "4717f484-afa1-460d-cdca-ec4c863d453e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: #1, MSE: 0.278002\n",
            "Epoch: #2, MSE: 0.242796\n",
            "Epoch: #3, MSE: 0.209606\n",
            "Epoch: #4, MSE: 0.172917\n",
            "Epoch: #5, MSE: 0.138358\n",
            "Epoch: #6, MSE: 0.115121\n",
            "Epoch: #7, MSE: 0.100658\n",
            "Epoch: #8, MSE: 0.089797\n",
            "Epoch: #9, MSE: 0.081016\n",
            "Epoch: #10, MSE: 0.073872\n",
            "Epoch: #11, MSE: 0.067948\n",
            "Epoch: #12, MSE: 0.062908\n",
            "Epoch: #13, MSE: 0.058524\n",
            "Epoch: #14, MSE: 0.054647\n",
            "Epoch: #15, MSE: 0.051183\n",
            "Epoch: #16, MSE: 0.048064\n",
            "Epoch: #17, MSE: 0.045242\n",
            "Epoch: #18, MSE: 0.042678\n",
            "Epoch: #19, MSE: 0.040341\n",
            "Epoch: #20, MSE: 0.038206\n",
            "Epoch: #21, MSE: 0.036249\n",
            "Epoch: #22, MSE: 0.034452\n",
            "Epoch: #23, MSE: 0.032798\n",
            "Epoch: #24, MSE: 0.031272\n",
            "Epoch: #25, MSE: 0.029860\n",
            "Epoch: #26, MSE: 0.028553\n",
            "Epoch: #27, MSE: 0.027339\n",
            "Epoch: #28, MSE: 0.026210\n",
            "Epoch: #29, MSE: 0.025158\n",
            "Epoch: #30, MSE: 0.024176\n",
            "Epoch: #31, MSE: 0.023257\n",
            "Epoch: #32, MSE: 0.022397\n",
            "Epoch: #33, MSE: 0.021590\n",
            "Epoch: #34, MSE: 0.020832\n",
            "Epoch: #35, MSE: 0.020118\n",
            "Epoch: #36, MSE: 0.019446\n",
            "Epoch: #37, MSE: 0.018812\n",
            "Epoch: #38, MSE: 0.018213\n",
            "Epoch: #39, MSE: 0.017646\n",
            "Epoch: #40, MSE: 0.017109\n",
            "Epoch: #41, MSE: 0.016600\n",
            "Epoch: #42, MSE: 0.016117\n",
            "Epoch: #43, MSE: 0.015658\n",
            "Epoch: #44, MSE: 0.015222\n",
            "Epoch: #45, MSE: 0.014806\n",
            "Epoch: #46, MSE: 0.014410\n",
            "Epoch: #47, MSE: 0.014032\n",
            "Epoch: #48, MSE: 0.013672\n",
            "Epoch: #49, MSE: 0.013327\n",
            "Epoch: #50, MSE: 0.012998\n",
            "Epoch: #51, MSE: 0.012682\n",
            "Epoch: #52, MSE: 0.012380\n",
            "Epoch: #53, MSE: 0.012090\n",
            "Epoch: #54, MSE: 0.011813\n",
            "Epoch: #55, MSE: 0.011546\n",
            "Epoch: #56, MSE: 0.011290\n",
            "Epoch: #57, MSE: 0.011044\n",
            "Epoch: #58, MSE: 0.010807\n",
            "Epoch: #59, MSE: 0.010579\n",
            "Epoch: #60, MSE: 0.010359\n",
            "Epoch: #61, MSE: 0.010148\n",
            "Epoch: #62, MSE: 0.009944\n",
            "Epoch: #63, MSE: 0.009747\n",
            "Epoch: #64, MSE: 0.009558\n",
            "Epoch: #65, MSE: 0.009374\n",
            "Epoch: #66, MSE: 0.009197\n",
            "Epoch: #67, MSE: 0.009026\n",
            "Epoch: #68, MSE: 0.008860\n",
            "Epoch: #69, MSE: 0.008700\n",
            "Epoch: #70, MSE: 0.008545\n",
            "Epoch: #71, MSE: 0.008395\n",
            "Epoch: #72, MSE: 0.008250\n",
            "Epoch: #73, MSE: 0.008109\n",
            "Epoch: #74, MSE: 0.007972\n",
            "Epoch: #75, MSE: 0.007839\n",
            "Epoch: #76, MSE: 0.007711\n",
            "Epoch: #77, MSE: 0.007586\n",
            "Epoch: #78, MSE: 0.007465\n",
            "Epoch: #79, MSE: 0.007347\n",
            "Epoch: #80, MSE: 0.007232\n",
            "Epoch: #81, MSE: 0.007121\n",
            "Epoch: #82, MSE: 0.007013\n",
            "Epoch: #83, MSE: 0.006907\n",
            "Epoch: #84, MSE: 0.006805\n",
            "Epoch: #85, MSE: 0.006705\n",
            "Epoch: #86, MSE: 0.006608\n",
            "Epoch: #87, MSE: 0.006513\n",
            "Epoch: #88, MSE: 0.006421\n",
            "Epoch: #89, MSE: 0.006331\n",
            "Epoch: #90, MSE: 0.006244\n",
            "Epoch: #91, MSE: 0.006159\n",
            "Epoch: #92, MSE: 0.006075\n",
            "Epoch: #93, MSE: 0.005994\n",
            "Epoch: #94, MSE: 0.005915\n",
            "Epoch: #95, MSE: 0.005837\n",
            "Epoch: #96, MSE: 0.005762\n",
            "Epoch: #97, MSE: 0.005688\n",
            "Epoch: #98, MSE: 0.005616\n",
            "Epoch: #99, MSE: 0.005545\n",
            "Epoch: #100, MSE: 0.005477\n",
            "Epoch: #101, MSE: 0.005409\n",
            "Epoch: #102, MSE: 0.005343\n",
            "Epoch: #103, MSE: 0.005279\n",
            "Epoch: #104, MSE: 0.005216\n",
            "Epoch: #105, MSE: 0.005155\n",
            "Epoch: #106, MSE: 0.005094\n",
            "Epoch: #107, MSE: 0.005035\n",
            "Epoch: #108, MSE: 0.004978\n",
            "Epoch: #109, MSE: 0.004921\n",
            "Epoch: #110, MSE: 0.004866\n",
            "Epoch: #111, MSE: 0.004811\n",
            "Epoch: #112, MSE: 0.004758\n",
            "Epoch: #113, MSE: 0.004706\n",
            "Epoch: #114, MSE: 0.004655\n",
            "Epoch: #115, MSE: 0.004605\n",
            "Epoch: #116, MSE: 0.004556\n",
            "Epoch: #117, MSE: 0.004508\n",
            "Epoch: #118, MSE: 0.004461\n",
            "Epoch: #119, MSE: 0.004414\n",
            "Epoch: #120, MSE: 0.004369\n",
            "Epoch: #121, MSE: 0.004324\n",
            "Epoch: #122, MSE: 0.004281\n",
            "Epoch: #123, MSE: 0.004238\n",
            "Epoch: #124, MSE: 0.004196\n",
            "Epoch: #125, MSE: 0.004154\n",
            "Epoch: #126, MSE: 0.004114\n",
            "Epoch: #127, MSE: 0.004074\n",
            "Epoch: #128, MSE: 0.004035\n",
            "Epoch: #129, MSE: 0.003996\n",
            "Epoch: #130, MSE: 0.003958\n",
            "Epoch: #131, MSE: 0.003921\n",
            "Epoch: #132, MSE: 0.003885\n",
            "Epoch: #133, MSE: 0.003849\n",
            "Epoch: #134, MSE: 0.003813\n",
            "Epoch: #135, MSE: 0.003779\n",
            "Epoch: #136, MSE: 0.003745\n",
            "Epoch: #137, MSE: 0.003711\n",
            "Epoch: #138, MSE: 0.003678\n",
            "Epoch: #139, MSE: 0.003646\n",
            "Epoch: #140, MSE: 0.003614\n",
            "Epoch: #141, MSE: 0.003582\n",
            "Epoch: #142, MSE: 0.003551\n",
            "Epoch: #143, MSE: 0.003521\n",
            "Epoch: #144, MSE: 0.003491\n",
            "Epoch: #145, MSE: 0.003461\n",
            "Epoch: #146, MSE: 0.003432\n",
            "Epoch: #147, MSE: 0.003404\n",
            "Epoch: #148, MSE: 0.003376\n",
            "Epoch: #149, MSE: 0.003348\n",
            "Epoch: #150, MSE: 0.003321\n",
            "Epoch: #151, MSE: 0.003294\n",
            "Epoch: #152, MSE: 0.003267\n",
            "Epoch: #153, MSE: 0.003241\n",
            "Epoch: #154, MSE: 0.003216\n",
            "Epoch: #155, MSE: 0.003190\n",
            "Epoch: #156, MSE: 0.003165\n",
            "Epoch: #157, MSE: 0.003141\n",
            "Epoch: #158, MSE: 0.003116\n",
            "Epoch: #159, MSE: 0.003093\n",
            "Epoch: #160, MSE: 0.003069\n",
            "Epoch: #161, MSE: 0.003046\n",
            "Epoch: #162, MSE: 0.003023\n",
            "Epoch: #163, MSE: 0.003000\n",
            "Epoch: #164, MSE: 0.002978\n",
            "Epoch: #165, MSE: 0.002956\n",
            "Epoch: #166, MSE: 0.002934\n",
            "Epoch: #167, MSE: 0.002913\n",
            "Epoch: #168, MSE: 0.002892\n",
            "Epoch: #169, MSE: 0.002871\n",
            "Epoch: #170, MSE: 0.002851\n",
            "Epoch: #171, MSE: 0.002830\n",
            "Epoch: #172, MSE: 0.002810\n",
            "Epoch: #173, MSE: 0.002791\n",
            "Epoch: #174, MSE: 0.002771\n",
            "Epoch: #175, MSE: 0.002752\n",
            "Epoch: #176, MSE: 0.002733\n",
            "Epoch: #177, MSE: 0.002714\n",
            "Epoch: #178, MSE: 0.002696\n",
            "Epoch: #179, MSE: 0.002677\n",
            "Epoch: #180, MSE: 0.002659\n",
            "Epoch: #181, MSE: 0.002642\n",
            "Epoch: #182, MSE: 0.002624\n",
            "Epoch: #183, MSE: 0.002607\n",
            "Epoch: #184, MSE: 0.002590\n",
            "Epoch: #185, MSE: 0.002573\n",
            "Epoch: #186, MSE: 0.002556\n",
            "Epoch: #187, MSE: 0.002539\n",
            "Epoch: #188, MSE: 0.002523\n",
            "Epoch: #189, MSE: 0.002507\n",
            "Epoch: #190, MSE: 0.002491\n",
            "Epoch: #191, MSE: 0.002475\n",
            "Epoch: #192, MSE: 0.002460\n",
            "Epoch: #193, MSE: 0.002444\n",
            "Epoch: #194, MSE: 0.002429\n",
            "Epoch: #195, MSE: 0.002414\n",
            "Epoch: #196, MSE: 0.002399\n",
            "Epoch: #197, MSE: 0.002384\n",
            "Epoch: #198, MSE: 0.002370\n",
            "Epoch: #199, MSE: 0.002355\n",
            "Epoch: #200, MSE: 0.002341\n",
            "Epoch: #201, MSE: 0.002327\n",
            "Epoch: #202, MSE: 0.002313\n",
            "Epoch: #203, MSE: 0.002300\n",
            "Epoch: #204, MSE: 0.002286\n",
            "Epoch: #205, MSE: 0.002273\n",
            "Epoch: #206, MSE: 0.002259\n",
            "Epoch: #207, MSE: 0.002246\n",
            "Epoch: #208, MSE: 0.002233\n",
            "Epoch: #209, MSE: 0.002220\n",
            "Epoch: #210, MSE: 0.002208\n",
            "Epoch: #211, MSE: 0.002195\n",
            "Epoch: #212, MSE: 0.002183\n",
            "Epoch: #213, MSE: 0.002170\n",
            "Epoch: #214, MSE: 0.002158\n",
            "Epoch: #215, MSE: 0.002146\n",
            "Epoch: #216, MSE: 0.002134\n",
            "Epoch: #217, MSE: 0.002122\n",
            "Epoch: #218, MSE: 0.002111\n",
            "Epoch: #219, MSE: 0.002099\n",
            "Epoch: #220, MSE: 0.002088\n",
            "Epoch: #221, MSE: 0.002076\n",
            "Epoch: #222, MSE: 0.002065\n",
            "Epoch: #223, MSE: 0.002054\n",
            "Epoch: #224, MSE: 0.002043\n",
            "Epoch: #225, MSE: 0.002032\n",
            "Epoch: #226, MSE: 0.002021\n",
            "Epoch: #227, MSE: 0.002011\n",
            "Epoch: #228, MSE: 0.002000\n",
            "Epoch: #229, MSE: 0.001990\n",
            "Epoch: #230, MSE: 0.001979\n",
            "Epoch: #231, MSE: 0.001969\n",
            "Epoch: #232, MSE: 0.001959\n",
            "Epoch: #233, MSE: 0.001949\n",
            "Epoch: #234, MSE: 0.001939\n",
            "Epoch: #235, MSE: 0.001929\n",
            "Epoch: #236, MSE: 0.001919\n",
            "Epoch: #237, MSE: 0.001910\n",
            "Epoch: #238, MSE: 0.001900\n",
            "Epoch: #239, MSE: 0.001891\n",
            "Epoch: #240, MSE: 0.001881\n",
            "Epoch: #241, MSE: 0.001872\n",
            "Epoch: #242, MSE: 0.001863\n",
            "Epoch: #243, MSE: 0.001853\n",
            "Epoch: #244, MSE: 0.001844\n",
            "Epoch: #245, MSE: 0.001835\n",
            "Epoch: #246, MSE: 0.001827\n",
            "Epoch: #247, MSE: 0.001818\n",
            "Epoch: #248, MSE: 0.001809\n",
            "Epoch: #249, MSE: 0.001800\n",
            "Epoch: #250, MSE: 0.001792\n",
            "Epoch: #251, MSE: 0.001783\n",
            "Epoch: #252, MSE: 0.001775\n",
            "Epoch: #253, MSE: 0.001766\n",
            "Epoch: #254, MSE: 0.001758\n",
            "Epoch: #255, MSE: 0.001750\n",
            "Epoch: #256, MSE: 0.001742\n",
            "Epoch: #257, MSE: 0.001734\n",
            "Epoch: #258, MSE: 0.001726\n",
            "Epoch: #259, MSE: 0.001718\n",
            "Epoch: #260, MSE: 0.001710\n",
            "Epoch: #261, MSE: 0.001702\n",
            "Epoch: #262, MSE: 0.001694\n",
            "Epoch: #263, MSE: 0.001687\n",
            "Epoch: #264, MSE: 0.001679\n",
            "Epoch: #265, MSE: 0.001672\n",
            "Epoch: #266, MSE: 0.001664\n",
            "Epoch: #267, MSE: 0.001657\n",
            "Epoch: #268, MSE: 0.001649\n",
            "Epoch: #269, MSE: 0.001642\n",
            "Epoch: #270, MSE: 0.001635\n",
            "Epoch: #271, MSE: 0.001628\n",
            "Epoch: #272, MSE: 0.001621\n",
            "Epoch: #273, MSE: 0.001614\n",
            "Epoch: #274, MSE: 0.001607\n",
            "Epoch: #275, MSE: 0.001600\n",
            "Epoch: #276, MSE: 0.001593\n",
            "Epoch: #277, MSE: 0.001586\n",
            "Epoch: #278, MSE: 0.001579\n",
            "Epoch: #279, MSE: 0.001573\n",
            "Epoch: #280, MSE: 0.001566\n",
            "Epoch: #281, MSE: 0.001559\n",
            "Epoch: #282, MSE: 0.001553\n",
            "Epoch: #283, MSE: 0.001546\n",
            "Epoch: #284, MSE: 0.001540\n",
            "Epoch: #285, MSE: 0.001534\n",
            "Epoch: #286, MSE: 0.001527\n",
            "Epoch: #287, MSE: 0.001521\n",
            "Epoch: #288, MSE: 0.001515\n",
            "Epoch: #289, MSE: 0.001508\n",
            "Epoch: #290, MSE: 0.001502\n",
            "Epoch: #291, MSE: 0.001496\n",
            "Epoch: #292, MSE: 0.001490\n",
            "Epoch: #293, MSE: 0.001484\n",
            "Epoch: #294, MSE: 0.001478\n",
            "Epoch: #295, MSE: 0.001472\n",
            "Epoch: #296, MSE: 0.001466\n",
            "Epoch: #297, MSE: 0.001461\n",
            "Epoch: #298, MSE: 0.001455\n",
            "Epoch: #299, MSE: 0.001449\n",
            "Epoch: #300, MSE: 0.001443\n",
            "Accuracy: 100.00%\n",
            "Data ouput: \n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "Predicted output: \n",
            "[[0.04112823]\n",
            " [0.96121657]\n",
            " [0.96482312]\n",
            " [0.03660937]]\n",
            "Predicted output round: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted output train: \\n\" + str(nn.predict(X)))\n",
        "test = [\n",
        "    [2,0],\n",
        "    [0,-1],\n",
        "    [45,203],\n",
        "    [-21,0],\n",
        "    [0,85],\n",
        "    [0,-328],\n",
        "]\n",
        "y_test = [[1], [0], [1], [0], [1], [0]]\n",
        "pred = nn.predict(test)\n",
        "print(\"Predicted output test: \\n\" + str(pred))\n",
        "mse = np.mean(np.square(y_test - pred))\n",
        "print(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtik_IapOdmP",
        "outputId": "f2171d1e-f9c0-4ed6-92a0-a01eaaea3be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted output train: \n",
            "[[0.04112823]\n",
            " [0.96121657]\n",
            " [0.96482312]\n",
            " [0.03660937]]\n",
            "Predicted output test: \n",
            "[[0.89730846]\n",
            " [0.02266876]\n",
            " [0.82448414]\n",
            " [0.09977334]\n",
            " [0.82448414]\n",
            " [0.06686296]]\n",
            "0.014516071855846392\n"
          ]
        }
      ]
    }
  ]
}